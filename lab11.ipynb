{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Feature Engineering & Cross-Validation\n",
    "\n",
    "In this lab, you will gain practice with using the scikit learn library to do some feature engineering and how to use cross-validation to produce a model with the least error for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from IPython.display import display, Latex, Markdown\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('lab11.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "For this lab, we will be using a toy dataset to predict the house prices in Boston with data provided by the `sklearn.datasets` package.\n",
    "\n",
    "Run the following cell to load the data. This will return a dictionary object which includes keys for:\n",
    "    - `data` : the data to learn\n",
    "    - `target` : the response vector\n",
    "    - `feature_names`: the column names\n",
    "    - `DESCR` : a full description of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_data = load_boston()\n",
    "print(boston_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A look at the `DESCR` attribute tells us the data contains these features:\n",
    "\n",
    "    1. CRIM      per capita crime rate by town\n",
    "    2. ZN        proportion of residential land zoned for lots over \n",
    "                 25,000 sq.ft.\n",
    "    3. INDUS     proportion of non-retail business acres per town\n",
    "    4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "                 river; 0 otherwise)\n",
    "    5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "    6. RM        average number of rooms per dwelling\n",
    "    7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "    8. DIS       weighted distances to five Boston employment centres\n",
    "    9. RAD       index of accessibility to radial highways\n",
    "    10. TAX      full-value property-tax rate per 10,000 USD\n",
    "    11. PTRATIO  pupil-teacher ratio by town\n",
    "    12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "                 by town\n",
    "    13. LSTAT    % lower status of the population\n",
    "    \n",
    "Let's now convert this data into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(boston_data.data, columns=boston_data.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Let's train some data! Before we can do this however, we need to split our data into a training set and validation set. These hold out points will be used to choose our best model. Additionally, remember that the response vector (housing prices) lives separate of the data in the `target` attribute.\n",
    "\n",
    "Use the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to split out one third of the training data for validation. Call the resulting datasets `X_train`, `X_test`, `Y_train`, `Y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "X = boston\n",
    "Y = pd.Series(boston_data.target)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = ...\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q01"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q01')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "As a warmup, let's regress a line to this data using `sklearn`. We've imported `sklearn.linear_model` as lm, so you can use that instead of typing out the whole module name. Running the cell should create a scatter plot for our predictions vs the true prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "linear_clf = ...\n",
    "\n",
    "# Fit your classifier\n",
    "linear_clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predict points from our test set\n",
    "Y_pred = linear_clf.predict(X_test)\n",
    "\n",
    "# Plot predicted vs true prices\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Prices\")\n",
    "plt.ylabel(\"Predicted prices\")\n",
    "plt.title(\"Prices vs Predicted prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "As shown from the scatter plot, our model is not perfect. Ideally, we would see a line of slope 1 from the points if our model was 100% accurate.\n",
    "\n",
    "Now let's also compute our mean squared error. Fill out the function below and compute the MSE for our predictions on both the training data `X_train` and the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def mse(predicted_y, actual_y):\n",
    "    return ...\n",
    "\n",
    "train_error = ...\n",
    "test_error = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q03')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "We have just executed a linear regression on our data. Can we get this predictor to be any better though? The following sections will go through cross-validation and some feature engineering in order to try and produce the best model with the least error.\n",
    "\n",
    "Let's start by seeing what is the **single** best feature for predicting boston house prices. For each feature in the given features list, fit a Linear Regression model to the training set where just that feature is selected for and check its accuracy on the validation set. Use the `mse` function you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "features = boston_data.feature_names\n",
    "\n",
    "# Your code to find the single best feature\n",
    "...\n",
    "\n",
    "best_feature, best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q04"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q04')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds Cross Validation\n",
    "\n",
    "We've so far been working with the generalized method of cross-validation where we split our data into a test and train set. Now let's try k-folds cross-validation to select the best subset of features for our model. Recall the approach looks something like:\n",
    "\n",
    "<img src=\"cv.png\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "For the sake of this lab, we have a provided a list of feature subsets and will try to find out which subset produces the best model predictor. In future assignments (Project 2?!?!), you will be given the full feature set and use EDA and other techniques you've learned in this class to select your set of best features.\n",
    "\n",
    "Here are the necessary steps to find your best linear predictor:\n",
    "\n",
    "1. Use the [`KFold.split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function to get 4 splits on your training data. Note that `split` returns the indices of the data for that split.\n",
    "2. For each split, select out the rows and columns based on the split indices and features.\n",
    "3. Compute the MSE from your prediction.\n",
    "4. Based on the set with that gave the smallest MSE, choose your best set of features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "feature_sets = [['TAX', 'INDUS', 'CRIM'], ['RM', 'LSTAT', 'PTRATIO'], ['RM', 'B', 'NOX'], ['TAX', 'LSTAT', 'DIS']]\n",
    "\n",
    "kf = ...\n",
    "splits = \n",
    "\n",
    "def compute_error(train_idx, valid_idx, features):\n",
    "    '''\n",
    "    Splits the original training data based on the passed in indices.\n",
    "    Fits the data to the split's train set and returns the MSE \n",
    "    \n",
    "    Args:\n",
    "        train_idx (array): Indices of the split training data\n",
    "        valid_idx (array): Indicies of the split validation data\n",
    "        features (array): List of features (strings)\n",
    "\n",
    "    Returns:\n",
    "        Returns the MSE of predictions on the validation data\n",
    "    '''\n",
    "    return\n",
    "    \n",
    "# Your code to find the best feature set based on the error\n",
    "...\n",
    "        \n",
    "best_feature_set = ...\n",
    "best_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q05"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q05')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Finally, fit a linear classifier using your best feature set and predict housing prices for your original test set. Compute the final MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Fit your classifier\n",
    "...\n",
    "\n",
    "# Predict points from our test set and calculate the mse\n",
    "final_mse = ...\n",
    "final_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "test",
     "q06"
    ]
   },
   "outputs": [],
   "source": [
    "_ = ok.grade('q06')\n",
    "_ = ok.backup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! You've used kfolds cross-validation to fit an accurate linear regression model to the dataset.\n",
    "\n",
    "In the future, you'd probably want to use something like [`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) to automatically perform cross-validation, but it's instructive to do it yourself at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log into OkPy.\n",
    "# You might need to change this to ok.auth(force=True) if you get an error\n",
    "ok.auth(force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Run the cell below to run all the OkPy tests at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Running all tests...\")\n",
    "_ = ok.grade_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to submit your assignment to OkPy. The autograder should email you shortly with your autograded score. The autograder will only run once every 30 minutes.\n",
    "\n",
    "**If you're failing tests on the autograder but pass them locally**, you should simulate the autograder by doing the following:\n",
    "\n",
    "1. In the top menu, click Kernel -> Restart and Run all.\n",
    "2. Run the cell above to run each OkPy test.\n",
    "\n",
    "**You must make sure that you pass all the tests when running steps 1 and 2 in order.** If you are still failing autograder tests, you should double check your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = ok.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
